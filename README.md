ðŸŽµ Emotion-Based Music Recommendation System
This project is a real-time Emotion-Based Music Recommendation System that detects users' facial expressions using a webcam and recommends personalized music based on their emotional state. It combines deep learning for emotion recognition with a content-based recommendation engine using Spotify song features.

ðŸ“Œ Features
ðŸŽ¥ Real-time facial emotion detection using ResNet architecture

ðŸŽ§ Personalized music recommendations using K-Nearest Neighbors (KNN)

ðŸ”„ Emotion-to-genre mapping for mood-based music curation

âš¡ Fast response: < 5 seconds from detection to song suggestion

ðŸŽµ Integration with Spotify via Spotify URIs

ðŸ’» Simple web-based interface built with Streamlit

ðŸ› ï¸ Technologies Used
Python

OpenCV

ResNet (for facial emotion detection)

K-Nearest Neighbors (KNN)

Pandas & NumPy

Spotify Tracks Dataset

Streamlit (for GUI)

ðŸš€ How to Run
Clone the Repository
git clone https://github.com/yourusername/emotion-music-recommendation.git
cd emotion-music-recommendation

Install Dependencies
pip install -r requirements.txt

Run the App
streamlit run app.py
ðŸ§  How It Works
User enables webcam.

Facial emotion is detected using a trained ResNet model.

The emotion is mapped to a suitable genre (e.g., Happy â†’ Pop).

Songs are filtered by genre and release year.

KNN identifies songs with similar audio features (danceability, energy, valence, tempo).

Spotify URI is used to suggest tracks that match the userâ€™s mood.

ðŸ“ˆ Future Scope
Multimodal emotion detection (voice, body language)

Deep learning-based recommendation engine

Cross-platform support (Apple Music, YouTube Music)

Social sharing and group playlist features

Gamified mood tracking and analytics

Stronger privacy and ethical safeguards
